---
title: 'Import - Lithic analysis from three sites: Balver HÃ¶hle, Buhlen & Ramioul '
author: "Lisa Schunk"
date: "`r Sys.Date()`"
output:
  word_document: default
---


```{r Knitr Options, include = FALSE}
knitr::opts_chunk$set(comment = NA, message = FALSE, indent = "", error = TRUE)
```


---

# Goal of the script
This script reads the three xlsx files (database techno-typological analysis) and formats the data for a statistical analysis.  
The script will:

1. Read in the original xlsx files 
2. Change and sort the data  in order to do stats 
3. Save the data as a new single xlsx file and R object


```{r}
dir_in <-  "analysis/all_sites/raw_data/"
dir_out <- "analysis/all_sites/derived_data/"
```

Raw data must be located in "`r dir_in`".  
Formatted data will be saved in "`r dir_out`".
The knit directory for this script is the project directory.

---


# Load packages
```{r}
library(openxlsx)
library(readxl)
library(R.utils)
library(tools)
library(data.table)
library(chron)
library(dplyr)
```


---

# Get name, path and information of the files
```{r}
data_files <- list.files(dir_in, pattern = "\\.xlsx$", full.names = TRUE)
md5_in <- md5sum(data_files)
info_in <- data.frame(files = basename(names(md5_in)), checksum = md5_in, 
                      row.names = NULL)
```

The checksum (MD5 hashes) of the imported files are:  
```{r, echo = FALSE}
info_in
```


# Read in original xlsx-files
```{r}
imp_data <- vector(mode = "list", length = length(data_files))
names(imp_data) <- basename(data_files)

# loop for import data due to the three different CSV files 
for (i in seq_along(data_files)) {
  imp_data[[i]] <- read.xlsx(data_files[i], sheet = 1, colNames = TRUE,
                      rowNames = FALSE, skipEmptyCols = FALSE)
}
str(imp_data)

# check pairwisely if the three lines of headers are identical among the datasets
# merges the data based on the three lines of headers while they get only 
# used in the first CSV file 
comp <- all(sapply(list(names(imp_data[[1]]), names(imp_data[[2]])), 
                   FUN = identical, names(imp_data[[3]])))
merged_data <- do.call(rbind, imp_data)

str(merged_data)

# adds indices as row names 
row.names(merged_data) <- 1:nrow(merged_data)

```

# Data analsysis - sorting  
## Dimension
```{r}
# keeps only columns relevant for dimensions and sorts them based on 
# their technological class
keep_col <- c(1:2, 4:5, 19:21)
dimensions <- merged_data[, keep_col] %>% arrange(technological.class)

KM_dimensions <- dimensions[4:333, ] 
PS_dimensions <- dimensions[493:546, ] 
LSS_dimensions <- dimensions[334:492, ]

```


## Perimeter
```{r}
# keeps only columns relevant for perimeter measurements and sorts them 
# based on their technological class
keep_col <- c(1:2, 4:5,7,23:26)
perimeter <- merged_data[, keep_col] %>% arrange(technological.class)

KM_perimeter <- perimeter[4:333, ] %>% arrange(artefact.state)
PS_perimeter <- perimeter[493:546, ] 

```


## Raw material
```{r}
# keeps only columns relevant for raw material classification and sorts them 
# based on their technological class
keep_col <- c(1:2, 4:5, 3)
raw_material <- merged_data[, keep_col] %>% arrange(technological.class)

KM_raw_material <- raw_material[4:333, ] %>% arrange(artefact.state)
PS_raw_material <- raw_material[493:546, ] %>% arrange(artefact.state)
LSS_raw_material <- raw_material[334:492, ] %>% arrange(artefact.state)

```

## Cortex + blanks 
```{r}
# keeps only columns relevant for cortex and blank classification and sorts them 
# based on their technological class
keep_col <- c(1:2, 4:5, 6, 8:10)
cortex_blanks <- merged_data[, keep_col] %>% arrange(technological.class)

KM_cortex_blanks <- cortex_blanks[4:333, ] %>% arrange(artefact.state)
PS_cortex_blanks <- cortex_blanks[493:546, ] %>% arrange(artefact.state)

```

## Back 
```{r}
# keeps only columns relevant for back modifications and sorts them based 
# on their technological class
keep_col <- c(1:2, 4:5, 11, 27)
back <- merged_data[, keep_col] %>% arrange(technological.class)

KM_back <- back[4:333, ] %>% arrange(artefact.state) 
PS_back <- back[493:546, ] %>% arrange(artefact.state)

```

## Edge retouch
```{r}
# keeps only columns relevant for edge retouch classification and sorts them 
# based on their technological class
keep_col <- c(1:2, 4:5, 12:13, 29)
edge_retouch <- merged_data[, keep_col] %>% arrange(technological.class)

KM_edge_retouch <- edge_retouch[4:333, ] %>% arrange(artefact.state)
PS_edge_retouch <- edge_retouch[493:546,] %>% arrange(artefact.state)

```

## Morpho type  
```{r}
# keeps only columns relevant for morpho type classification and sorts them 
# based on their technological class
keep_col <- c(1:2, 4:5, 7, 19:21)
morpho.type <- merged_data[, keep_col] %>% arrange(technological.class)

KM_morpho.type <- morpho.type[4:333, ] %>% arrange(artefact.state)
PS_morpho.type <- morpho.type[493:546, ] %>% arrange(artefact.state)

```

## Application 'Pradnik method'  
```{r}
# keeps only columns relevant for 'morpho type 'Pradnik method' classification 
# and sorts them based on their technological class
keep_col <- c(1:2, 4:5, 15:16)
Pradnik.method <- merged_data[, keep_col] %>% arrange(technological.class)

KM_Pradnik.method <- Pradnik.method[4:333, ] %>% arrange(artefact.state)
PS_Pradnik.method <- Pradnik.method[493:546, ]  %>% arrange(artefact.state)

```


## Lateralisation
```{r}
# keeps only columns relevant for lateralisation and sorts them based on their
# technological class
keep_col <- c(1:2, 4:5, 18)
lateralisation <- merged_data[, keep_col] %>% arrange(technological.class)

KM_lateralisation <- lateralisation[4:333, ] %>% arrange(artefact.state)
PS_lateralisation <- lateralisation[493:546, ] %>% arrange(artefact.state)

```


# Type lateral sharpening spall 
```{r}
# keeps only columns relevant for lateral sharpening spall classification and sorts 
# them based on their technological class
keep_col <- c(1:2, 4:5, 17:18)
lss_type <- merged_data[, keep_col] %>% arrange(technological.class)

LSS_type <- lss_type[334:492, ] %>% arrange(artefact.state)

```

# Save data
## Format name of output file
```{r}
file_out <- "all_sites_analysis"
```
The files will be saved as "`r paste0("~/", file_out, ".[ext]")`".


## Write to XLSX
```{r}
write.xlsx(list(data = merged_data, dimensions = dimensions, KM_dimensions = KM_dimensions,  
                  PS_dimensions = PS_dimensions, LSS_dimensions = LSS_dimensions, KM_perimeter = 
                  KM_perimeter, PS_perimeter = PS_perimeter, KM_raw_material = KM_raw_material,
                  PS_raw_material = PS_raw_material, LSS_raw_material = LSS_raw_material, 
                  KM_cortex_blanks = KM_cortex_blanks, PS_cortex_blanks = PS_cortex_blanks, 
                  KM_back = KM_back, PS_back = PS_back, KM_edge_retouch = KM_edge_retouch, 
                  PS_edge_retouch = PS_edge_retouch, KM_morpho.type = KM_morpho.type, 
                  PS_morpho.type = PS_morpho.type, KM_Pradnik.method = KM_Pradnik.method, 
                  PS_Pradnik.method = PS_Pradnik.method, KM_lateralisation = KM_lateralisation, 
                  PS_lateralisation = PS_lateralisation, LSS_type = LSS_type), 
                  file = paste0(dir_out, file_out, ".xlsx"))
```


## Save R object
```{r}
saveObject(merged_data, file = paste0(dir_out, file_out, ".Rbin"))
```


## Show file information
```{r}
file_out <- c(paste0(dir_out, file_out, ".xlsx"), paste0(dir_out, file_out, ".Rbin"))
md5_out <- md5sum(file_out)
info_out <- data.frame(files = basename(names(md5_out)), checksum = md5_out, 
                       row.names = NULL)
```

The checksum (MD5 hashes) of the exported files are:  
```{r, echo = FALSE}
info_out
```


---

# sessionInfo() and RStudio version

```{r}
sessionInfo()
```

RStudio version `r readLines("analysis/all_sites/scripts/RStudioVersion.txt", n = 1)`.


---


END OF SCRIPT